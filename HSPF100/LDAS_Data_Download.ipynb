{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50251548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seattle is in contiguous USA\n",
      "NLDAS:NLDAS_FORA0125_H_2_0_Tair\n",
      "Downloading ATEMP data for grid: Seattle\n",
      "Seattle is in contiguous USA\n",
      "NLDAS:NLDAS_FORA0125_H_2_0_Rainf\n",
      "Downloading PRECIP data for grid: Seattle\n",
      "['Allahabad', 25.43, 81.84, 5.5] is outside contiguous USA\n",
      "GLDAS2:GLDAS_NOAH025_3H_2_1_Tair_f_inst\n",
      "Downloading ATEMP data for grid: Allahabad\n",
      "['Allahabad', 25.43, 81.84, 5.5] is outside contiguous USA\n",
      "GLDAS2:GLDAS_NOAH025_3H_2_1_Rainf_f_tavg\n",
      "Downloading PRECIP data for grid: Allahabad\n",
      "['Asmara', 15.33, 38.92, 3] is outside contiguous USA\n",
      "GLDAS2:GLDAS_NOAH025_3H_2_1_Tair_f_inst\n",
      "Downloading ATEMP data for grid: Asmara\n",
      "['Asmara', 15.33, 38.92, 3] is outside contiguous USA\n",
      "GLDAS2:GLDAS_NOAH025_3H_2_1_Rainf_f_tavg\n",
      "Downloading PRECIP data for grid: Asmara\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Mar 26 16:10:29 2020\n",
    "Updated on 2026-02-16\n",
    "\n",
    "@author: Anurag\n",
    "\n",
    "This example script downloads the GLDAS and NLDAS data for a couple of stations, \n",
    "adjust the time zone and saves them in a WDM file.\n",
    "Please refer to the tsgettoolbox documentation for more data sources.\n",
    "https://timcera.bitbucket.io/tsgettoolbox/docsrc/index.html#tsgettoolbox-documentation\n",
    "\"\"\"\n",
    "\n",
    "from tsgettoolbox import tsgettoolbox as tsget\n",
    "from wdmtoolbox import wdmtoolbox as wdm\n",
    "\n",
    "def convertunitforHSPF(constituent, df, LDAS_var):\n",
    "    '''This function is for unit conversion'''\n",
    "    if constituent == \"ATEMP\": df = (df-273)\n",
    "    #From K to degC\n",
    "    if constituent == \"PRECIP\" and 'GLDAS' in LDAS_var: \n",
    "        df = df * 3600 \n",
    "        #From kg/m^2/s to mm/hour\n",
    "        #Assuming that 1 kg/m^2 is close to 1 mm\n",
    "        df=df*3\n",
    "            #GLDAS is 3 hourly data. THis changes values from \n",
    "            #mm/hour to total precip for each times step of 3 hours.\n",
    "            #There might be a better way to accomplish this task\n",
    "    elif constituent == \"PRECIP\" and 'NLDAS' in LDAS_var:\n",
    "        df=df\n",
    "        #No change needed for NLDAS            \n",
    "    \n",
    "    return df\n",
    "    \n",
    "StationList=[['Seattle',47.629605, -122.348941,-8],\n",
    "            ['Allahabad', 25.43,81.84,5.5],\n",
    "            ['Asmara',15.33, 38.92,3]]\n",
    "\n",
    "#Each station is a list of station name, lat, long and TimeZone\n",
    "#adjustment.\n",
    "\n",
    "\n",
    "Constituent=['ATEMP','PRECIP']\n",
    "#Please refer to the GLDAS2 documentation below for more constituents.\n",
    "#https://hydro1.gesdisc.eosdis.nasa.gov/data/GLDAS/README_GLDAS2.pdf\n",
    "\n",
    "GLDAS_ConstituentDetails={\n",
    "                    \"PRECIP\":[\"Precipitation\",\"mm\",\n",
    "                    \"GLDAS2:GLDAS_NOAH025_3H_2_1_Rainf_f_tavg\",\"kg/m^2/s\"],\n",
    "                    \"ATEMP\":[\"Air Temperature\",\"Fahrenheit\",\n",
    "                    \"GLDAS2:GLDAS_NOAH025_3H_2_1_Tair_f_inst\",\"K\"]\n",
    "                    }\n",
    "\n",
    "NLDAS_ConstituentDetails={\n",
    "                    \"PRECIP\":[\"Precipitation\",\"mm\",\n",
    "                    \"NLDAS:NLDAS_FORA0125_H_2_0_Rainf\",\"mm\"],\n",
    "                    \"ATEMP\":[\"Air Temperature\",\"Fahrenheit\",\n",
    "                    \"NLDAS:NLDAS_FORA0125_H_2_0_Tair\",\"K\"]\n",
    "                    }\n",
    "\n",
    "#If you add more constituents, you will need to expland this dict\n",
    "\n",
    "UStop = 49.3457868 # north lat\n",
    "USleft = -124.7844079 # west long\n",
    "USright = -66.9513812 # east long\n",
    "USbottom =  24.7433195 # south lat\n",
    "#US Lat and long coordinates\n",
    "\n",
    "WDMFileName='MetData_20260215.wdm'\n",
    "wdm.createnewwdm(WDMFileName, overwrite=True)\n",
    "index = 1\n",
    "from datetime import datetime\n",
    "with open(\"MetLog.txt\", 'w') as Logfile:\n",
    "    Logfile.write(\"Started Downloading the data at \"\n",
    "                + datetime.isoformat(datetime.now()) + \" and saving in \"\n",
    "                + WDMFileName + \"\\n\")\n",
    "    for station in StationList:\n",
    "        # Going through Each Station in the list\n",
    "        TimeZoneAdjustment = station[3]\n",
    "        Logfile.write(\"Station: \" + station[0] + \", Latitude: \" + str(station[1])\n",
    "                        + \", Longitude: \" + str(station[2])\n",
    "                        + \", TimeZoneAdjustment: \" + str(TimeZoneAdjustment)\n",
    "                        + \"\\n\")\n",
    "\n",
    "        for const in Constituent:\n",
    "            #Going through each constituent\n",
    "            if station[1]<UStop and station[1]>USbottom and \\\n",
    "                station[2]>USleft and station[2]<USright:\n",
    "                LDAS_variable = NLDAS_ConstituentDetails[const][2]  \n",
    "                TimeStep=1  \n",
    "                print(f'{station[0]} is in contiguous USA')\n",
    "            else:\n",
    "                LDAS_variable = GLDAS_ConstituentDetails[const][2]\n",
    "                TimeStep=3\n",
    "                print(f'{station} is outside contiguous USA')\n",
    "            print(LDAS_variable)\n",
    "            stationID = station\n",
    "            print(\"Downloading \" + const + \" data for grid: \" + station[0]) \n",
    "            df = tsget.ldas(lat=station[1], lon=station[2],\n",
    "                               variables=LDAS_variable,\n",
    "                               startDate=\"2018-12-31\",\n",
    "                               endDate=\"2019-1-31\")\n",
    "            column_name = df.columns[0]\n",
    "            df = df[column_name]\n",
    "            df.dropna()\n",
    "            df = convertunitforHSPF(const,df, LDAS_variable)\n",
    "            wdm.createnewdsn(WDMFileName, index,\n",
    "                                constituent=const,\n",
    "                                scenario=\"OBSERVED\",location=station[0][0:8],\n",
    "                                tcode=3, statid=station[0], tsstep=TimeStep,\n",
    "                                description=LDAS_variable)\n",
    "            #Creating an empty dataset in WDM File\n",
    "            \n",
    "            wdm.csvtowdm(WDMFileName, index, input_ts=df)\n",
    "            #saving the data in the DSN created in previous line\n",
    "            \n",
    "            Logfile.write(\"Constituent: \" + const + \", Column Name:\"\n",
    "            + column_name + \", DSN: \" + str(index) + \"\\n\")\n",
    "            index += 1\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
